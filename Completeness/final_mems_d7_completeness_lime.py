# -*- coding: utf-8 -*-
"""final mems/d7 completeness lime .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13uuIpEGMk__1tZ_kwLRBV_JZ4SbnQWK2
"""

pip install lime

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, auc
from sklearn.preprocessing import label_binarize
from sklearn.metrics import f1_score, accuracy_score
from sklearn.utils import shuffle
from imblearn.over_sampling import RandomOverSampler
import lime
import time
from collections import Counter
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
import lime.lime_tabular


# Define oversampling function
def oversample(X, y):
    ros = RandomOverSampler(random_state=42)
    X_resampled, y_resampled = ros.fit_resample(X, y)
    return X_resampled, y_resampled

# Load dataset
data = pd.read_csv("device7_top_20_features.csv")
# MEMS
#data = pd.read_csv("mems_dataset.csv")
#data.pop('time')

y = data.pop('label')

print('---------------------------------------------------------------------------------')
print('Normalizing database')
print('---------------------------------------------------------------------------------')
print('')


# Initialize the MinMaxScaler
scaler = MinMaxScaler()

# Fit and transform the DataFrame
scaled_data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)
data = scaled_data
data = data.assign( label = y)

# Rename labels for better readability
# MEMS
#label_map = {1: 'Normal', 2: 'Near-failure', 3: 'Failure'}
label_map = {1: 'benign', 2: 'gafgyt.combo', 3: 'gafgyt.junk', 4: 'gafgyt.scan', 5: 'gafgyt.tcp', 6: 'gafgyt.udp'} # mems change

data['label'] = data['label'].map(label_map)

# Separate features and labels
X = data.drop('label', axis=1)
# MEMS
#X = data[['x', 'y', 'z']]

y = data['label']

# Define model parameters
max_depth = 5
n_estimators = 5
min_samples_split = 2

# Define XAI parameters
output_file_name = "Completeness_d7_LIME.txt" # rename

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize Random Forest classifier
rf_classifier = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, min_samples_split=min_samples_split, n_jobs=-1)

# Initialize SHAP explainer
explainer = None

# Model training
print('Training the model')
start = time.time()
rf_classifier.fit(X_train, y_train)
end = time.time()
print('ELAPSED TIME MODEL TRAINING:', (end - start) / 60, 'min')

# Model prediction
print('Predicting using the model')
start = time.time()
y_pred = rf_classifier.predict(X_test)
end = time.time()
print('ELAPSED TIME MODEL PREDICTION:', (end - start) / 60, 'min')

# Evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average='weighted')
conf_matrix = confusion_matrix(y_test, y_pred)
# MEMS
#roc_auc = roc_auc_score(label_binarize(y_test, classes=['Normal', 'Near-failure', 'Failure']),
 #                       label_binarize(y_pred, classes=['Normal', 'Near-failure', 'Failure']), average='macro')
# IOT d7
roc_auc = roc_auc_score(label_binarize(y_test, classes=['benign','gafgyt.combo','gafgyt.junk','gafgyt.scan','gafgyt.tcp','gafgyt.udp']),
                       label_binarize(y_pred, classes=['benign','gafgyt.combo','gafgyt.junk','gafgyt.scan','gafgyt.tcp','gafgyt.udp']), average='macro')

# Write outputs to file
with open(output_file_name, "a") as f:
    print('---------------------------------------------------------------------------------', file=f)
    print('Training the model', file=f)
    print('ELAPSED TIME MODEL TRAINING:', (end - start) / 60, 'min', file=f)
    print('Predicting using the model', file=f)
    print('ELAPSED TIME MODEL PREDICTION:', (end - start) / 60, 'min', file=f)
    print('Accuracy:', accuracy, file=f)
    print('F1 Score:', f1, file=f)
    print('Confusion Matrix:', file=f)
    print(conf_matrix, file=f)
    print('ROC AUC Score:', roc_auc, file=f)

#filters

# MEMS
# normal_samples = data[data['label'] == 'Normal']
# near_failure_samples = data[data['label'] == 'Near-failure']
# failure_samples = data[data['label'] == 'Failure']

# normal_y = normal_samples.pop('label')
# near_failure_y = near_failure_samples.pop('label')
# failure_y = failure_samples.pop('label')

#d7
benign_samples = data[data['label'] == 'benign']
gafgyt_combo_samples = data[data['label'] == 'gafgyt.combo']
gafgyt_junk_samples = data[data['label'] == 'gafgyt.junk']
gafgyt_scan_samples = data[data['label'] == 'gafgyt.scan']
gafgyt_tcp_samples = data[data['label'] == 'gafgyt.tcp']
gafgyt_udp_samples = data[data['label'] == 'gafgyt.udp']

benign_y = benign_samples.pop('label')
gafgyt_combo_y = gafgyt_combo_samples.pop('label')
gafgyt_junk_y = gafgyt_junk_samples.pop('label')
gafgyt_scan_y = gafgyt_scan_samples.pop('label')
gafgyt_tcp_y = gafgyt_tcp_samples.pop('label')
gafgyt_udp_y = gafgyt_udp_samples.pop('label')



x_axis = [0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1]

label = ['benign','gafgyt.combo','gafgyt.junk','gafgyt.scan','gafgyt.tcp','gafgyt.udp']
#label = ['Normal','Near-failure', 'Failure']

req_cols = X_test.columns
df = data
test2 = X_test
X_test = X_test.to_numpy()

#Define function to test sample with the waterfall plot
def lime_explanator(sample):
    # print(sample)
    sample_df = sample
    sample = sample.to_numpy()
    # print(sample)
    sample = sample[0]
    # print(sample)

    explainer = lime.lime_tabular.LimeTabularExplainer(X_test, feature_names= list(test2.columns.values) , class_names=label , discretize_continuous=True)
                                                # feature_names= list(test2.columns.values) # d7
                                                # feature_names= ['x','y','z']
    #creating dict
    feat_list = req_cols[:-1]
    # print(feat_list)

    c = 0

    num_columns = df.shape[1] - 1
    feature_name = req_cols[:-1] #d7
    # feature_name = req_cols #mems
    # print('feature name value:', feature_name)
    feature_name.sort_values()
    # print('features after sorting:', feature_name.sort_values())
    feature_val = []
    feature_val_abs = []
    samples = 1

    position =  np.argmax(rf_classifier.predict_proba(((sample_df))))
    prediction = label[position]


    for i in range(0,num_columns):
        feature_val.append(0)
        feature_val_abs.append(0)

    # for i in range(0,samples):

    # i = sample
        # exp = explainer.explain_instance(test[i], rf.predict_proba)

    exp = explainer.explain_instance(sample, rf_classifier.predict_proba, num_features=num_columns, top_labels=len(label))
    # exp.show_in_notebook(show_table=True, show_all=True)

    lime_list = exp.as_list(position)
    lime_list.sort()

    for i in range(0,len(lime_list)):
        #---------------------------------------------------
        #fix
        my_string = lime_list[i][0]
        for index, char in enumerate(my_string):
            if char.isalpha():
                first_letter_index = index
                break  # Exit the loop when the first letter is found

        my_string = my_string[first_letter_index:]
        modified_tuple = list(lime_list[i])
        modified_tuple[0] = my_string
        lime_list[i] = tuple(modified_tuple)

        #---------------------------------------------------

    lime_list.sort()
    # print(lime_list)
    # for j in range (0,num_columns): feature_val[j]+= abs(lime_list[j][1])
    for j in range (0,num_columns):feature_val_abs[j] = abs(lime_list[j][1])
    for j in range (0,num_columns):feature_val[j] = lime_list[j][1]
    c = c + 1
    # print ('progress',100*(c/samples),'%')

    # Define the number you want to divide by
    # divider = samples

    # Use a list comprehension to divide all elements by the same number
    # feature_val = [x / divider for x in feature_val]

    # for item1, item2 in zip(feature_name, feature_val):
    #     print(item1, item2)


    # Use zip to combine the two lists, sort based on list1, and then unzip them
    zipped_lists = list(zip(feature_name, feature_val,feature_val_abs))
    zipped_lists.sort(key=lambda x: x[2],reverse=True)

    # Convert the sorted result back into separate lists
    sorted_list1, sorted_list2,sorted_list3 = [list(x) for x in zip(*zipped_lists)]
    feature_name = sorted_list1
    lime_val = sorted_list2
    # print('feature names:', feature_name)

    return (prediction, lime_val,feature_name)

def completeness_all(single_class_samples,number_samples, number_of_features_pertubation):
    Bucket = {
    '0.0': 0,
    '0.1':0,
    '0.2':0,
    '0.3':0,
    '0.4':0,
    '0.5':0,
    '0.6':0,
    '0.7':0,
    '0.8':0,
    '0.9':0,
    '1.0':0,

           }
    Counter_all_samples = 0
    counter_samples_changed_class = 0
    print('------------------------------------------------')
    print('Initiating Completeness Experiment')
    print('------------------------------------------------')
    for i in range(0,number_samples):
        #select sample
        try:
            sample = single_class_samples[i:i+1]
        except:
            break # break if there more samples requested than samples in the dataset
        # Explanate the original sample
        u = lime_explanator(sample)
        #select top 5 features from the original sample
        top_k_features = []
        top_k_features.append(u[2][0]) #append first feature
        break_condition = False
        for k in range(1,number_of_features_pertubation):
            for j in range(11):  # 11 steps to include 1.0 (0 to 10)
                if break_condition == True: break
                perturbation = j / 10.0  # Divide by 10 to get steps of 0.1
                try:temp_var = sample[top_k_features[k-1]]
                except: None
                result = np.where((temp_var - perturbation) < 0, True, False)
                if result < 0:
                    sample[top_k_features[k-1]] = 1 - perturbation
                else:
                    try:sample[top_k_features[k-1]] = temp_var - perturbation
                    except: None

                # sample[top_k_features[k-1]] = perturbation
                v = lime_explanator(sample)
                if v[0] != u[0]:
                    Bucket[str(perturbation)] += 1
                    break_condition = True
                    counter_samples_changed_class += 1
                    break
                else: sample[top_k_features[k-1]] = abs(temp_var - 1) # set the sample feature value as the symetric opposite
            #print('Test value:', u[2][k])
            top_k_features.append(u[2][k]) #append second, third feature .. and so on
            if break_condition == True: break
        Counter_all_samples += 1
        progress  = 100*Counter_all_samples/number_samples
        if progress%10 == 0: print('Progress', progress ,'%')
        # if progress >= 1: break
    # print('Number of Normal samples that changed classification: ',counter_samples_changed_class)
    # print('Number of all samples analyzed: ',Counter_all_samples)
    dict = Bucket
    temp = 0
    for k in dict:
        dict[k] = dict[k] + temp
        temp = dict[k]
    total = number_samples
    y_axis = []
    for k in dict:
        dict[k] = abs(dict[k] - total)
        y_axis.append(dict[k]/total)
    # print('return values:', counter_samples_changed_class,Counter_all_samples,y_axis )
    return(counter_samples_changed_class,Counter_all_samples,y_axis)

X_test

K_samples = 1000 #or desired value always ; 1 is for testing
K_feat = 5 # d7
# K_feat = 3

K_feat

num_samples = K_samples
num_feat_pertubation = K_feat

"""**MEMS**"""

p = completeness_all(normal_samples,num_samples,num_feat_pertubation)
percentage = 100*p[0]/p[1]
y_axis_normal = p[2]
with open(output_file_name, "a") as f:
     print('y_axis_normal: ', p[2], file=f)
     print(p, file=f)
     print('Number of Normal samples that changed classification: ',p[0], file=f)
     print('Number of all samples analyzed: ',p[1], file=f)
     print(percentage,'%','- samples are complete ',file=f)

p = completeness_all(near_failure_samples,num_samples,num_feat_pertubation)
percentage = 100*p[0]/p[1]
y_axis_near_failure = p[2]
with open(output_file_name, "a") as f:
     print('y_axis_near_failure: ', p[2], file=f)
     print(p, file=f)
     print('Number of near_failure samples that changed classification: ',p[0], file=f)
     print('Number of all samples analyzed: ',p[1], file=f)
     print(percentage,'%','- samples are complete ',file=f)

p = completeness_all(failure_samples,num_samples,num_feat_pertubation)
percentage = 100*p[0]/p[1]
y_axis_failure = p[2]
with open(output_file_name, "a") as f:
     print('y_axis_failure: ', p[2], file=f)
     print(p, file=f)
     print('Number of failure samples that changed classification: ',p[0], file=f)
     print('Number of all samples analyzed: ',p[1], file=f)
     print(percentage,'%','- samples are complete ',file=f)

plt.clf()

# Plot the first line
plt.plot(x_axis, y_axis_normal, label='normal', color='blue', linestyle='--', marker='o')

# # Plot the second line
plt.plot(x_axis, y_axis_near_failure, label='near_failure', color='red', linestyle='--', marker='x')

# # Plot the third line
plt.plot(x_axis, y_axis_failure, label='failure', color='green', linestyle='--', marker='s')

# Enable grid lines (both major and minor grids)
plt.grid()

# Add labels and a legend
plt.xlabel('Perturbations')
plt.ylabel('Samples remaining')
plt.legend()

# Show the plot
plt.show()
plt.savefig('mems_completeness_LIME.png')
plt.clf()

"""**DEVICE 7**"""

p = completeness_all(benign_samples,num_samples,num_feat_pertubation)
percentage = 100*p[0]/p[1]
y_axis_benign = p[2]
with open(output_file_name, "a") as f:
     print('y_axis_benign: ', p[2], file=f)
     print(p, file=f)
     print('Number of Benign samples that changed classification: ',p[0], file=f)
     print('Number of all samples analyzed: ',p[1], file=f)
     print(percentage,'%','- samples are complete ',file=f)

p = completeness_all(gafgyt_combo_samples,num_samples,num_feat_pertubation)
percentage = 100*p[0]/p[1]
y_axis_gafgyt_combo = p[2]
with open(output_file_name, "a") as f:
     print('y_axis_gafgyt_combo: ', p[2], file=f)
     print(p, file=f)
     print('Number of gafgyt_combo samples that changed classification: ',p[0], file=f)
     print('Number of all samples analyzed: ',p[1], file=f)
     print(percentage,'%','- samples are complete ',file=f)

p = completeness_all(gafgyt_junk_samples,num_samples,num_feat_pertubation)
percentage = 100*p[0]/p[1]
y_axis_gafgyt_junk = p[2]
with open(output_file_name, "a") as f:
     print('y_axis_gafgyt_junk: ', p[2], file=f)
     print(p, file=f)
     print('Number of gafgyt_junk samples that changed classification: ',p[0], file=f)
     print('Number of all samples analyzed: ',p[1], file=f)
     print(percentage,'%','- samples are complete ',file=f)

p = completeness_all(gafgyt_scan_samples,num_samples,num_feat_pertubation)
percentage = 100*p[0]/p[1]
y_axis_gafgyt_scan = p[2]
with open(output_file_name, "a") as f:
     print('y_axis_gafgyt_scan: ', p[2], file=f)
     print(p, file=f)
     print('Number of gafgyt_scan samples that changed classification: ',p[0], file=f)
     print('Number of all samples analyzed: ',p[1], file=f)
     print(percentage,'%','- samples are complete ',file=f)

p = completeness_all(gafgyt_tcp_samples,num_samples,num_feat_pertubation)
percentage = 100*p[0]/p[1]
y_axis_gafgyt_tcp = p[2]
with open(output_file_name, "a") as f:
     print('y_axis_gafgyt_tcp: ', p[2], file=f)
     print(p, file=f)
     print('Number of gafgyt_tcp samples that changed classification: ',p[0], file=f)
     print('Number of all samples analyzed: ',p[1], file=f)
     print(percentage,'%','- samples are complete ',file=f)

p = completeness_all(gafgyt_udp_samples,num_samples,num_feat_pertubation)
percentage = 100*p[0]/p[1]
y_axis_gafgyt_udp = p[2]
with open(output_file_name, "a") as f:
     print('y_axis_gafgyt_udp: ', p[2], file=f)
     print(p, file=f)
     print('Number of gafgyt_udp samples that changed classification: ',p[0], file=f)
     print('Number of all samples analyzed: ',p[1], file=f)
     print(percentage,'%','- samples are complete ',file=f)

plt.clf()

# Plot the first line
plt.plot(x_axis, y_axis_benign, label='benign', color='blue', linestyle='--', marker='o')

# # Plot the second line
plt.plot(x_axis, y_axis_gafgyt_combo, label='gafgyt_combo', color='red', linestyle='--', marker='x')

# # Plot the third line
plt.plot(x_axis, y_axis_gafgyt_junk, label='gafgyt_junk', color='green', linestyle='--', marker='s')

# # Plot the fourth line
plt.plot(x_axis, y_axis_gafgyt_scan, label='gafgyt_scan', color='purple', linestyle='--', marker='p')

# # Plot the fifth line
plt.plot(x_axis, y_axis_gafgyt_tcp, label='gafgyt_tcp', color='orange', linestyle='--', marker='h')

# # Plot the sixth line
plt.plot(x_axis, y_axis_gafgyt_udp, label='gafgyt_udp', color='magenta', linestyle='--', marker='+')

# Enable grid lines (both major and minor grids)
plt.grid()

# Customize grid lines (optional)
# plt.grid()

# Add labels and a legend
plt.xlabel('Perturbations')
plt.ylabel('Samples remaining')
plt.legend()

# Set the title of the plot
# plt.title('Accuracy x Features - SHAP SML')

# Show the plot
plt.show()
plt.savefig('d7_Completeness_LIME.png')
plt.clf()