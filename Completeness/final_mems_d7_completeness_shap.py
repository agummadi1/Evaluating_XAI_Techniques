# -*- coding: utf-8 -*-
"""final mems/d7 completeness shap .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Thq_4rq-SdqkaB5Rhq-FbMIoyqe33IHX
"""

pip install shap

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, auc
from sklearn.preprocessing import label_binarize
from sklearn.metrics import f1_score, accuracy_score
from sklearn.utils import shuffle
from imblearn.over_sampling import RandomOverSampler
import shap
import time
from collections import Counter
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler


# Define oversampling function
def oversample(X, y):
    ros = RandomOverSampler(random_state=42)
    X_resampled, y_resampled = ros.fit_resample(X, y)
    return X_resampled, y_resampled

# Load dataset | uncomment according to dataset
# MEMS
data = pd.read_csv("mems_dataset.csv")
df_max_scaled = data
data.pop('time')
y = data.pop('label')

# IoT d7
# data = pd.read_csv("device7_top_20_features.csv")
# df_max_scaled = data
# y = data.pop('label')


print('---------------------------------------------------------------------------------')
print('Normalizing database')
print('---------------------------------------------------------------------------------')
print('')


# Initialize the MinMaxScaler
scaler = MinMaxScaler()

# Fit and transform the DataFrame
scaled_df = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)
data = scaled_df

data = data.assign( label = y)

# Rename labels for better readability | uncomment according to dataset
# MEMS
label_map = {1: 'Normal', 2: 'Near-failure', 3: 'Failure'}
# IoT d7
#label_map = {1: 'benign', 2: 'gafgyt.combo', 3: 'gafgyt.junk', 4: 'gafgyt.scan', 5: 'gafgyt.tcp', 6: 'gafgyt.udp'}

data['label'] = data['label'].map(label_map)

# Separate features and labels | uncomment according to dataset
# MEMS
X = data[['x', 'y', 'z']]
# IoT d7
# X = data.drop(columns=['label'])

y = data['label']

# Define model parameters
max_depth = 5
n_estimators = 5
min_samples_split = 2

# Define XAI parameters
output_file_name = "final_Completeness_mems_SHAP.txt" # mems rename

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize Random Forest classifier
rf_classifier = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, min_samples_split=min_samples_split, n_jobs=-1)

# Initialize SHAP explainer
explainer = None

# Model training
print('Training the model')
start = time.time()
rf_classifier.fit(X_train, y_train)
end = time.time()
print('ELAPSED TIME MODEL TRAINING:', (end - start) / 60, 'min')

# Model prediction
print('Predicting using the model')
start = time.time()
y_pred = rf_classifier.predict(X_test)
end = time.time()
print('ELAPSED TIME MODEL PREDICTION:', (end - start) / 60, 'min')

# Evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average='weighted')
conf_matrix = confusion_matrix(y_test, y_pred)
# MEMS
roc_auc = roc_auc_score(label_binarize(y_test, classes=['Normal', 'Near-failure', 'Failure']),
                        label_binarize(y_pred, classes=['Normal', 'Near-failure', 'Failure']), average='macro')
# IOT d7
#roc_auc = roc_auc_score(label_binarize(y_test, classes=['benign','gafgyt.combo','gafgyt.junk','gafgyt.scan','gafgyt.tcp','gafgyt.udp']),
                     #   label_binarize(y_pred, classes=['benign','gafgyt.combo','gafgyt.junk','gafgyt.scan','gafgyt.tcp','gafgyt.udp']), average='macro')

# Write outputs to file
with open(output_file_name, "a") as f:
    print('---------------------------------------------------------------------------------', file=f)
    print('Training the model', file=f)
    print('ELAPSED TIME MODEL TRAINING:', (end - start) / 60, 'min', file=f)
    print('Predicting using the model', file=f)
    print('ELAPSED TIME MODEL PREDICTION:', (end - start) / 60, 'min', file=f)
    print('Accuracy:', accuracy, file=f)
    print('F1 Score:', f1, file=f)
    print('Confusion Matrix:', file=f)
    print(conf_matrix, file=f)
    print('ROC AUC Score:', roc_auc, file=f)

#filters

# MEMS
normal_samples = data[data['label'] == 'Normal']
near_failure_samples = data[data['label'] == 'Near-failure']
failure_samples = data[data['label'] == 'Failure']

normal_y = normal_samples.pop('label')
near_failure_y = near_failure_samples.pop('label')
failure_y = failure_samples.pop('label')

#d7
# benign_samples = data[data['label'] == 'benign']
# gafgyt_combo_samples = data[data['label'] == 'gafgyt.combo']
# gafgyt_junk_samples = data[data['label'] == 'gafgyt.junk']
# gafgyt_scan_samples = data[data['label'] == 'gafgyt.scan']
# gafgyt_tcp_samples = data[data['label'] == 'gafgyt.tcp']
# gafgyt_udp_samples = data[data['label'] == 'gafgyt.udp']

# benign_y = benign_samples.pop('label')
# gafgyt_combo_y = gafgyt_combo_samples.pop('label')
# gafgyt_junk_y = gafgyt_junk_samples.pop('label')
# gafgyt_scan_y = gafgyt_scan_samples.pop('label')
# gafgyt_tcp_y = gafgyt_tcp_samples.pop('label')
# gafgyt_udp_y = gafgyt_udp_samples.pop('label')

x_axis = [0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1]

label = ['Normal','Near-failure', 'Failure']
#label = ['benign','gafgyt.combo','gafgyt.junk','gafgyt.scan','gafgyt.tcp','gafgyt.udp']

#Define function to test sample with the waterfall plot
def waterfall_explanator(sample):
    # datapoint to explain
    explainer = shap.TreeExplainer(rf_classifier)
    prediction = rf_classifier.predict(sample)[0] # Prediction of the sample | label[] didnt work cz my code is already predicting string
    #extract the index accordingly to prediction
    index = label.index(prediction)
    #generating shap values explainer
    sv = explainer(sample)
    bv = explainer.expected_value[index]
    exp = shap.Explanation(sv[:,:,index], sv.base_values[:,index], sample, feature_names=X_test.columns.tolist())
    # generating plot
    # shap.waterfall_plot(exp[0],max_display=10,show= None)
    # plt.savefig('RF_Shap_Waterfall.png')
    # plt.clf()

    feature_importance = pd.DataFrame({
        'row_id': sample.index.values.repeat(sample.shape[1]),
        'feature': sample.columns.to_list() * sample.shape[0],
        'feature_value': sample.values.flatten(),
        'base_value': bv,
        'shap_values': sv.values[:,:,index].flatten()

    })

    feature_importance['shap_values'] = abs(feature_importance['shap_values'])
    feature_importance.sort_values(by=['shap_values'], ascending=False,inplace=True)
    feature_importance.head()
    shap_val = feature_importance['shap_values'].tolist()
    feature_val = feature_importance['feature_value'].tolist()
    feature_name = feature_importance['feature'].tolist()

    return (prediction, shap_val,feature_val,feature_name)

def completeness_all(single_class_samples,number_samples, number_of_features_pertubation):
    Bucket = {
    '0.0': 0,
    '0.1':0,
    '0.2':0,
    '0.3':0,
    '0.4':0,
    '0.5':0,
    '0.6':0,
    '0.7':0,
    '0.8':0,
    '0.9':0,
    '1.0':0,

           }
    # Counter_chart = 0
    Counter_all_samples = 0
    counter_samples_changed_class = 0
    print('------------------------------------------------')
    print('Initiating Completeness Experiment')
    print('------------------------------------------------')
    for i in range(0,number_samples):
        #select sample
        try:
            sample = single_class_samples[i:i+1]
        except:
            break # break if there more samples requested than samples in the dataset
        # Explanate the original sample
        u = waterfall_explanator(sample)
        #select top 5 features from the original sample
        top_k_features = []
        top_k_features.append(u[3][0]) #append first feature
        # print(u[3])
        break_condition = False
        for k in range(1,number_of_features_pertubation):
            for j in range(11):  # 11 steps to include 1.0 (0 to 10)
                if break_condition == True: break
                perturbation = j / 10.0  # Divide by 10 to get steps of 0.1
                temp_var = sample[top_k_features[k-1]]
                result = np.where((temp_var - perturbation) < 0, True, False)
                if result < 0:
                    sample[top_k_features[k-1]] = 1 - perturbation
                else: sample[top_k_features[k-1]] = temp_var - perturbation
                # sample[top_k_features[k-1]] = perturbation
                v = waterfall_explanator(sample)
                if v[0] != u[0]:
                    #print(str(perturbation))
                    Bucket[str(perturbation)] += 1
                    break_condition = True
                    counter_samples_changed_class += 1
                    # Bucket[str(perturbation)] = counter_samples_changed_class
                    break
                else: sample[top_k_features[k-1]] = abs(temp_var - 1) # set the sample feature value as the symetric opposite
            top_k_features.append(u[3][k]) #append second, third feature .. and so on
            if break_condition == True: break
        Counter_all_samples += 1
        progress  = 100*Counter_all_samples/number_samples
        if progress%10 == 0: print('Progress', progress ,'%')
    dict = Bucket
    temp = 0
    for k in dict:
        dict[k] = dict[k] + temp
        temp = dict[k]
    total = number_samples
    y_axis = []
    for k in dict:
        dict[k] = abs(dict[k] - total)
        y_axis.append(dict[k]/total)
    return(counter_samples_changed_class,Counter_all_samples,y_axis)

K_samples = 1000
K_feat = 3 # MEMS
#K_feat = 5 # d7

K_feat

num_samples = K_samples
num_feat_pertubation = K_feat

"""**DEVICE 7 RUNS**"""

p = completeness_all(benign_samples,num_samples,num_feat_pertubation)
percentage = 100*p[0]/p[1]
with open(output_file_name, "a") as f:
     print('y_axis_benign: ', p[2], file=f)
     print(p, file=f)
     print('Number of Benign samples that changed classification: ',p[0], file=f)
     print('Number of all samples analyzed: ',p[1], file=f)
     print(percentage,'%','- samples are complete ',file=f)

y_axis_benign = p[2]

p = completeness_all(gafgyt_combo_samples,num_samples,num_feat_pertubation)
percentage = 100*p[0]/p[1]
with open(output_file_name, "a") as f:
     print('y_axis_gafgyt_combo: ', p[2], file=f)
     print(p, file=f)
     print('Number of gafgyt_combo samples that changed classification: ',p[0], file=f)
     print('Number of all samples analyzed: ',p[1], file=f)
     print(percentage,'%','- samples are complete ',file=f)

y_axis_gafgyt_combo = p[2]

p = completeness_all(gafgyt_junk_samples,num_samples,num_feat_pertubation)
percentage = 100*p[0]/p[1]
with open(output_file_name, "a") as f:
     print('y_axis_gafgyt_junk: ', p[2], file=f)
     print(p, file=f)
     print('Number of gafgyt_junk samples that changed classification: ',p[0], file=f)
     print('Number of all samples analyzed: ',p[1], file=f)
     print(percentage,'%','- samples are complete ',file=f)

y_axis_gafgyt_junk = p[2]

p = completeness_all(gafgyt_scan_samples,num_samples,num_feat_pertubation)
percentage = 100*p[0]/p[1]
with open(output_file_name, "a") as f:
     print('y_axis_gafgyt_scan: ', p[2], file=f)
     print(p, file=f)
     print('Number of gafgyt_scan samples that changed classification: ',p[0], file=f)
     print('Number of all samples analyzed: ',p[1], file=f)
     print(percentage,'%','- samples are complete ',file=f)

y_axis_gafgyt_scan = p[2]

p = completeness_all(gafgyt_tcp_samples,num_samples,num_feat_pertubation)
percentage = 100*p[0]/p[1]
with open(output_file_name, "a") as f:
     print('y_axis_gafgyt_tcp: ', p[2], file=f)
     print(p, file=f)
     print('Number of gafgyt_tcp samples that changed classification: ',p[0], file=f)
     print('Number of all samples analyzed: ',p[1], file=f)
     print(percentage,'%','- samples are complete ',file=f)

y_axis_gafgyt_tcp = p[2]

p = completeness_all(gafgyt_udp_samples,num_samples,num_feat_pertubation)
percentage = 100*p[0]/p[1]
with open(output_file_name, "a") as f:
     print('y_axis_gafgyt_udp: ', p[2], file=f)
     print(p, file=f)
     print('Number of gafgyt_udp samples that changed classification: ',p[0], file=f)
     print('Number of all samples analyzed: ',p[1], file=f)
     print(percentage,'%','- samples are complete ',file=f)

y_axis_gafgyt_udp = p[2]

plt.clf()

# Plot the first line
plt.plot(x_axis, y_axis_benign, label='benign', color='blue', linestyle='--', marker='o')

# # Plot the second line
plt.plot(x_axis, y_axis_gafgyt_combo, label='gafgyt_combo', color='red', linestyle='--', marker='x')

# # Plot the third line
plt.plot(x_axis, y_axis_gafgyt_junk, label='gafgyt_junk', color='green', linestyle='--', marker='s')

# # Plot the fourth line
plt.plot(x_axis, y_axis_gafgyt_scan, label='gafgyt_scan', color='purple', linestyle='--', marker='p')

# # Plot the fifth line
plt.plot(x_axis, y_axis_gafgyt_tcp, label='gafgyt_tcp', color='orange', linestyle='--', marker='h')

# # Plot the sixth line
plt.plot(x_axis, y_axis_gafgyt_udp, label='gafgyt_udp', color='magenta', linestyle='--', marker='+')

# Enable grid lines (both major and minor grids)
plt.grid()

# Customize grid lines (optional)
# plt.grid()

# Add labels and a legend
plt.xlabel('Perturbations')
plt.ylabel('Samples remaining')
plt.legend()

# Set the title of the plot
# plt.title('Accuracy x Features - SHAP SML')

# Show the plot
plt.show()
plt.savefig('d7_SHAP_CIC.png')
plt.clf()

"""**MEMS RUNS**"""

p = completeness_all(normal_samples,num_samples,num_feat_pertubation)
percentage = 100*p[0]/p[1]
with open(output_file_name, "a") as f:
     print('y_axis_normal: ', p[2], file=f)
     print(p, file=f)
     print('Number of normal samples that changed classification: ',p[0], file=f)
     print('Number of all samples analyzed: ',p[1], file=f)
     print(percentage,'%','- samples are complete ',file=f)

y_axis_normal = p[2]

p = completeness_all(near_failure_samples,num_samples,num_feat_pertubation)
percentage = 100*p[0]/p[1]
y_axis_near_failure = p[2]
with open(output_file_name, "a") as f:
     print('y_axis_near_failure: ', p[2], file=f)
     print(p, file=f)
     print('Number of near_failure samples that changed classification: ',p[0], file=f)
     print('Number of all samples analyzed: ',p[1], file=f)
     print(percentage,'%','- samples are complete ',file=f)

p = completeness_all(failure_samples,num_samples,num_feat_pertubation)
percentage = 100*p[0]/p[1]
y_axis_failure = p[2]
with open(output_file_name, "a") as f:
     print('y_axis_failure: ', p[2], file=f)
     print(p, file=f)
     print('Number of failre samples that changed classification: ',p[0], file=f)
     print('Number of all samples analyzed: ',p[1], file=f)
     print(percentage,'%','- samples are complete ',file=f)

plt.clf()

# Plot the first line
plt.plot(x_axis, y_axis_normal, label='normal', color='blue', linestyle='--', marker='o')

# # Plot the second line
plt.plot(x_axis, y_axis_near_failure, label='near_failure', color='red', linestyle='--', marker='x')

# # Plot the third line
plt.plot(x_axis, y_axis_failure, label='failure', color='green', linestyle='--', marker='s')

# Enable grid lines (both major and minor grids)
plt.grid()

# Add labels and a legend
plt.xlabel('Perturbations')
plt.ylabel('Samples remaining')
plt.legend()

# Show the plot
plt.show()
plt.savefig('mems_completeness_SHAP.png')
plt.clf()